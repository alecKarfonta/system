# Ollama RTX 5090 Configuration
# Copy this file to .env and customize

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=0

# Memory Settings (adjust based on your needs)
OLLAMA_MAX_VRAM=32000000000
GPU_MEMORY_UTILIZATION=0.98
OLLAMA_GPU_MEMORY_UTILIZATION=0.98
CUDA_MEMORY_FRACTION=0.98

# Performance Tuning
OLLAMA_KV_CACHE_TYPE=q8_0
OLLAMA_NUM_PARALLEL=1
OLLAMA_FLASH_ATTENTION=1
OLLAMA_GPU_LAYERS=999
OLLAMA_NUM_GPU=1
OLLAMA_LLM_LIBRARY=cuda
OLLAMA_SCHED_SPREAD=false

# Network
OLLAMA_HOST=0.0.0.0:11434

# Model Configuration
PRIMARY_MODEL=qwen3:30b-a3b-instruct-2507-q4_K_M
CONTEXT_LENGTH=262000

# Optional: Hugging Face token for downloading models
# HUGGING_FACE_HUB_TOKEN=your_token_here
